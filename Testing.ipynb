{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing, metrics, decomposition, pipeline, dummy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import nltk\n",
    "import helpers.data_mining_helpers as dmh\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plz setting your own relative data_path for trainning set\n",
    "# plz import the necessary file by your own\n",
    "# or just comment out the part you don't need to import\n",
    "dir_data = 'data_set'\n",
    "\n",
    "f_train = os.path.join(dir_data, 'task1_trainset.csv')\n",
    "f_abstract_task = os.path.join(dir_data, 'abstract_task.csv')\n",
    "f_test = os.path.join(dir_data, 'task1_public_testset.csv')\n",
    "# f_test_split = os.path.join(dir_data, 'test_split.csv')\n",
    "f_test_submission = os.path.join(dir_data, 'task1_sample_submission.csv')\n",
    "\n",
    "# read file and convert into pandas dataframe\n",
    "train_data = pd.read_csv(f_train)\n",
    "abstract_task = pd.read_csv(f_abstract_task)\n",
    "test_data = pd.read_csv(f_test)\n",
    "# test_split = pd.read_csv(f_test_split)\n",
    "test_submission = pd.read_csv(f_test_submission)\n",
    "\n",
    "tasks = ['BACKGROUND', 'OBJECTIVES', 'METHODS', 'RESULTS', 'CONCLUSIONS', 'OTHERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Task</th>\n",
       "      <th>label</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>processed_sen</th>\n",
       "      <th>unigrams_no_stop_words</th>\n",
       "      <th>processed_sen_no_stop</th>\n",
       "      <th>Doc_no.</th>\n",
       "      <th>Num_of_sentences</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Rank%</th>\n",
       "      <th>Is_first</th>\n",
       "      <th>Is_last</th>\n",
       "      <th>BACKGROUND</th>\n",
       "      <th>OBJECTIVES</th>\n",
       "      <th>METHODS</th>\n",
       "      <th>RESULTS</th>\n",
       "      <th>CONCLUSIONS</th>\n",
       "      <th>OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rapid popularity of Internet of Things (IoT) a...</td>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>['BACKGROUND']</td>\n",
       "      <td>['rapid', 'popular', 'of', 'internet', 'of', '...</td>\n",
       "      <td>rapid popular of internet of thing ( iot ) and...</td>\n",
       "      <td>['rapid', 'popular', 'internet', 'thing', '(',...</td>\n",
       "      <td>rapid popular internet thing ( iot ) cloud com...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To ensure secure and reliable data communicati...</td>\n",
       "      <td>OBJECTIVES</td>\n",
       "      <td>['OBJECTIVES']</td>\n",
       "      <td>['to', 'ensur', 'secur', 'and', 'reliabl', 'da...</td>\n",
       "      <td>to ensur secur and reliabl data commun between...</td>\n",
       "      <td>['ensur', 'secur', 'reliabl', 'data', 'commun'...</td>\n",
       "      <td>ensur secur reliabl data commun end-to-end ( e...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This paper introduces a Neuro-Fuzzy based Brai...</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>['METHODS']</td>\n",
       "      <td>['thi', 'paper', 'introduc', 'a', 'neuro-fuzzi...</td>\n",
       "      <td>thi paper introduc a neuro-fuzzi base brain-in...</td>\n",
       "      <td>['paper', 'introduc', 'neuro-fuzzi', 'base', '...</td>\n",
       "      <td>paper introduc neuro-fuzzi base brain-inspir t...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The proposed TMM utilizes node behavioral trus...</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>['METHODS']</td>\n",
       "      <td>['the', 'propos', 'tmm', 'util', 'node', 'beha...</td>\n",
       "      <td>the propos tmm util node behavior trust and da...</td>\n",
       "      <td>['propos', 'tmm', 'util', 'node', 'behavior', ...</td>\n",
       "      <td>propos tmm util node behavior trust data trust...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In contrast to the existing fuzzy based TMMs, ...</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>['RESULTS']</td>\n",
       "      <td>['in', 'contrast', 'to', 'the', 'exist', 'fuzz...</td>\n",
       "      <td>in contrast to the exist fuzzi base tmm , the ...</td>\n",
       "      <td>['contrast', 'exist', 'fuzzi', 'base', 'tmm', ...</td>\n",
       "      <td>contrast exist fuzzi base tmm , ns2 simul resu...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence        Task  \\\n",
       "0  Rapid popularity of Internet of Things (IoT) a...  BACKGROUND   \n",
       "1  To ensure secure and reliable data communicati...  OBJECTIVES   \n",
       "2  This paper introduces a Neuro-Fuzzy based Brai...     METHODS   \n",
       "3  The proposed TMM utilizes node behavioral trus...     METHODS   \n",
       "4  In contrast to the existing fuzzy based TMMs, ...     RESULTS   \n",
       "\n",
       "            label                                           unigrams  \\\n",
       "0  ['BACKGROUND']  ['rapid', 'popular', 'of', 'internet', 'of', '...   \n",
       "1  ['OBJECTIVES']  ['to', 'ensur', 'secur', 'and', 'reliabl', 'da...   \n",
       "2     ['METHODS']  ['thi', 'paper', 'introduc', 'a', 'neuro-fuzzi...   \n",
       "3     ['METHODS']  ['the', 'propos', 'tmm', 'util', 'node', 'beha...   \n",
       "4     ['RESULTS']  ['in', 'contrast', 'to', 'the', 'exist', 'fuzz...   \n",
       "\n",
       "                                       processed_sen  \\\n",
       "0  rapid popular of internet of thing ( iot ) and...   \n",
       "1  to ensur secur and reliabl data commun between...   \n",
       "2  thi paper introduc a neuro-fuzzi base brain-in...   \n",
       "3  the propos tmm util node behavior trust and da...   \n",
       "4  in contrast to the exist fuzzi base tmm , the ...   \n",
       "\n",
       "                              unigrams_no_stop_words  \\\n",
       "0  ['rapid', 'popular', 'internet', 'thing', '(',...   \n",
       "1  ['ensur', 'secur', 'reliabl', 'data', 'commun'...   \n",
       "2  ['paper', 'introduc', 'neuro-fuzzi', 'base', '...   \n",
       "3  ['propos', 'tmm', 'util', 'node', 'behavior', ...   \n",
       "4  ['contrast', 'exist', 'fuzzi', 'base', 'tmm', ...   \n",
       "\n",
       "                               processed_sen_no_stop  Doc_no.  \\\n",
       "0  rapid popular internet thing ( iot ) cloud com...        1   \n",
       "1  ensur secur reliabl data commun end-to-end ( e...        1   \n",
       "2  paper introduc neuro-fuzzi base brain-inspir t...        1   \n",
       "3  propos tmm util node behavior trust data trust...        1   \n",
       "4  contrast exist fuzzi base tmm , ns2 simul resu...        1   \n",
       "\n",
       "   Num_of_sentences  Rank     Rank%  Is_first  Is_last  BACKGROUND  \\\n",
       "0                 6     1  0.166667         1        0           1   \n",
       "1                 6     2  0.333333         0        0           0   \n",
       "2                 6     3  0.500000         0        0           0   \n",
       "3                 6     4  0.666667         0        0           0   \n",
       "4                 6     5  0.833333         0        0           0   \n",
       "\n",
       "   OBJECTIVES  METHODS  RESULTS  CONCLUSIONS  OTHERS  \n",
       "0           0        0        0            0       0  \n",
       "1           1        0        0            0       0  \n",
       "2           0        1        0            0       0  \n",
       "3           0        1        0            0       0  \n",
       "4           0        0        1            0       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_task.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_task['label'] = abstract_task['Task'].apply(lambda t : t.split('/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_TO_CONVERT = 'processed_sen'\n",
    "# COL_TO_CONVERT = 'processed_sen_no_stop'\n",
    "\n",
    "FEATURES = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46867, 19127)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect, data_count = dmh.get_count_vect(abstract_task[COL_TO_CONVERT])\n",
    "data_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46867, 19127)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect, data_tfidf = dmh.get_tfidf_vect(abstract_task[COL_TO_CONVERT])\n",
    "data_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46867, 30000)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_count_vect, bi_data_count = dmh.get_count_vect \\\n",
    "    (abstract_task[COL_TO_CONVERT], max_features=FEATURES, ngram_range=(2,2))\n",
    "bi_data_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46867, 30000)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_tfidf_vect, bi_data_tfidf = dmh.get_tfidf_vect \\\n",
    "    (abstract_task[COL_TO_CONVERT], max_features=FEATURES, ngram_range=(2,2))\n",
    "bi_data_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVES', 'OTHERS',\n",
       "       'RESULTS'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform(abstract_task['label'])\n",
    "\n",
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, vstack, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = abstract_task\n",
    "N = len(df)\n",
    "feature_names = ['Num_of_sentences', 'Rank', 'Rank%', 'Is_first', 'Is_last']\n",
    "features = []\n",
    "\n",
    "for i in feature_names:\n",
    "    row = np.arange(N)\n",
    "    col = np.zeros(N)\n",
    "    data = df[i].values\n",
    "    f = csr_matrix((data, (row, col)), shape=(N, 1))\n",
    "    features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pclightyear\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning:\n",
      "\n",
      "The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5464577277463405"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross value score on naive bayes classifier\n",
    "\n",
    "X = hstack([data_count, bi_data_count])\n",
    "# X = hstack([data_tfidf, bi_data_tfidf])\n",
    "for f in features:\n",
    "    X = hstack([X, f])\n",
    "\n",
    "y = abstract_task['Task']\n",
    "\n",
    "clf = MultinomialNB()\n",
    "cross_val_score(clf, X, y, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4566538734966842"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross value score on decision tree classifier\n",
    "\n",
    "X = hstack([data_count, bi_data_count])\n",
    "# X = hstack([data_tfidf, bi_data_tfidf])\n",
    "for f in features:\n",
    "    X = hstack([X, f])\n",
    "y = y_train\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "cross_val_score(clf, X, y, cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build naive bayes classifier\n",
    "\n",
    "X = hstack([data_count, bi_data_count])\n",
    "# X = hstack([data_tfidf, bi_data_tfidf])\n",
    "for f in features:\n",
    "    X = hstack([X, f])\n",
    "\n",
    "y = abstract_task['Task']\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build decision tree classifier\n",
    "\n",
    "X = hstack([data_count, bi_data_count])\n",
    "# X = hstack([data_tfidf, bi_data_tfidf])\n",
    "for f in features:\n",
    "    X = hstack([X, f])\n",
    "    \n",
    "y = y_train\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### transforming testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>processed_sen</th>\n",
       "      <th>unigrams_no_stop_words</th>\n",
       "      <th>processed_sen_no_stop</th>\n",
       "      <th>Doc_no.</th>\n",
       "      <th>Num_of_sentences</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Rank%</th>\n",
       "      <th>Is_first</th>\n",
       "      <th>Is_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mobile Crowdsensing is a promising paradigm fo...</td>\n",
       "      <td>['mobil', 'crowdsens', 'is', 'a', 'promis', 'p...</td>\n",
       "      <td>mobil crowdsens is a promis paradigm for ubiqu...</td>\n",
       "      <td>['mobil', 'crowdsens', 'promis', 'paradigm', '...</td>\n",
       "      <td>mobil crowdsens promis paradigm ubiquit sens ,...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a fundamental property of Mobile Crowdsensi...</td>\n",
       "      <td>['as', 'a', 'fundament', 'properti', 'of', 'mo...</td>\n",
       "      <td>as a fundament properti of mobil crowdsens sys...</td>\n",
       "      <td>['fundament', 'properti', 'mobil', 'crowdsens'...</td>\n",
       "      <td>fundament properti mobil crowdsens system , te...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Therefore, a mechanism is required for the sys...</td>\n",
       "      <td>['therefor', ',', 'a', 'mechan', 'is', 'requir...</td>\n",
       "      <td>therefor , a mechan is requir for the system s...</td>\n",
       "      <td>['therefor', ',', 'mechan', 'requir', 'system'...</td>\n",
       "      <td>therefor , mechan requir system server recruit...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this paper, we develop a novel Cheating-Res...</td>\n",
       "      <td>['in', 'thi', 'paper', ',', 'we', 'develop', '...</td>\n",
       "      <td>in thi paper , we develop a novel cheating-res...</td>\n",
       "      <td>['paper', ',', 'develop', 'novel', 'cheating-r...</td>\n",
       "      <td>paper , develop novel cheating-resili incent (...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Via theoretical analysis, we demonstrate the c...</td>\n",
       "      <td>['via', 'theoret', 'analysi', ',', 'we', 'demo...</td>\n",
       "      <td>via theoret analysi , we demonstr the correct ...</td>\n",
       "      <td>['via', 'theoret', 'analysi', ',', 'demonstr',...</td>\n",
       "      <td>via theoret analysi , demonstr correct design .</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  Mobile Crowdsensing is a promising paradigm fo...   \n",
       "1  As a fundamental property of Mobile Crowdsensi...   \n",
       "2  Therefore, a mechanism is required for the sys...   \n",
       "3  In this paper, we develop a novel Cheating-Res...   \n",
       "4  Via theoretical analysis, we demonstrate the c...   \n",
       "\n",
       "                                            unigrams  \\\n",
       "0  ['mobil', 'crowdsens', 'is', 'a', 'promis', 'p...   \n",
       "1  ['as', 'a', 'fundament', 'properti', 'of', 'mo...   \n",
       "2  ['therefor', ',', 'a', 'mechan', 'is', 'requir...   \n",
       "3  ['in', 'thi', 'paper', ',', 'we', 'develop', '...   \n",
       "4  ['via', 'theoret', 'analysi', ',', 'we', 'demo...   \n",
       "\n",
       "                                       processed_sen  \\\n",
       "0  mobil crowdsens is a promis paradigm for ubiqu...   \n",
       "1  as a fundament properti of mobil crowdsens sys...   \n",
       "2  therefor , a mechan is requir for the system s...   \n",
       "3  in thi paper , we develop a novel cheating-res...   \n",
       "4  via theoret analysi , we demonstr the correct ...   \n",
       "\n",
       "                              unigrams_no_stop_words  \\\n",
       "0  ['mobil', 'crowdsens', 'promis', 'paradigm', '...   \n",
       "1  ['fundament', 'properti', 'mobil', 'crowdsens'...   \n",
       "2  ['therefor', ',', 'mechan', 'requir', 'system'...   \n",
       "3  ['paper', ',', 'develop', 'novel', 'cheating-r...   \n",
       "4  ['via', 'theoret', 'analysi', ',', 'demonstr',...   \n",
       "\n",
       "                               processed_sen_no_stop  Doc_no.  \\\n",
       "0  mobil crowdsens promis paradigm ubiquit sens ,...        0   \n",
       "1  fundament properti mobil crowdsens system , te...        0   \n",
       "2  therefor , mechan requir system server recruit...        0   \n",
       "3  paper , develop novel cheating-resili incent (...        0   \n",
       "4    via theoret analysi , demonstr correct design .        0   \n",
       "\n",
       "   Num_of_sentences  Rank     Rank%  Is_first  Is_last  \n",
       "0                 7     0  0.000000         1        0  \n",
       "1                 7     1  0.142857         0        0  \n",
       "2                 7     2  0.285714         0        0  \n",
       "3                 7     3  0.428571         0        0  \n",
       "4                 7     4  0.571429         0        0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_split\n",
    "\n",
    "COL_TO_CONVERT = 'processed_sen'\n",
    "# COL_TO_CONVERT = 'processed_sen_no_stop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131166, 19127)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_count = count_vect.transform(df[COL_TO_CONVERT])\n",
    "test_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131166, 19127)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tfidf = tfidf_vect.transform(df[COL_TO_CONVERT])\n",
    "test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131166, 30000)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_test_count = bi_count_vect.transform(df[COL_TO_CONVERT])\n",
    "bi_test_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131166, 30000)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_test_tfidf = bi_tfidf_vect.transform(df[COL_TO_CONVERT])\n",
    "bi_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = test_split\n",
    "N = len(df)\n",
    "feature_names = ['Num_of_sentences', 'Rank', 'Rank%', 'Is_first', 'Is_last']\n",
    "features = []\n",
    "\n",
    "for i in feature_names:\n",
    "    row = np.arange(N)\n",
    "    col = np.zeros(N)\n",
    "    data = df[i].values\n",
    "    f = csr_matrix((data, (row, col)), shape=(N, 1))\n",
    "    features.append(f)\n",
    "\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = hstack([test_count, bi_test_count])\n",
    "# X_test = hstack([test_tfidf, bi_test_tfidf])\n",
    "for f in features:\n",
    "    X_test = hstack([X_test, f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131166"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BACKGROUND', 'BACKGROUND', 'BACKGROUND', 'OBJECTIVES', 'RESULTS'],\n",
       "      dtype='<U49')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVES', 'OTHERS',\n",
       "       'RESULTS'], dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改用 at 比較快?\n",
    "\n",
    "for i, y in enumerate(y_pred):\n",
    "    test_submission.at[i, 'BACKGROUND'] = y[0]\n",
    "    test_submission.at[i, 'OBJECTIVES'] = y[3]\n",
    "    test_submission.at[i, 'METHODS'] = y[2]\n",
    "    test_submission.at[i, 'RESULTS'] = y[5]\n",
    "    test_submission.at[i, 'CONCLUSIONS'] = y[1]\n",
    "    test_submission.at[i, 'OTHERS'] = y[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(y_pred):\n",
    "    categories = p.split('/')\n",
    "    \n",
    "    for c in categories:\n",
    "        test_submission.at[i, c] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>BACKGROUND</th>\n",
       "      <th>OBJECTIVES</th>\n",
       "      <th>METHODS</th>\n",
       "      <th>RESULTS</th>\n",
       "      <th>CONCLUSIONS</th>\n",
       "      <th>OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T00001_S001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T00001_S002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T00001_S003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T00001_S004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T00001_S005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      order_id  BACKGROUND  OBJECTIVES  METHODS  RESULTS  CONCLUSIONS  OTHERS\n",
       "0  T00001_S001           1           0        0        0            0       0\n",
       "1  T00001_S002           1           0        0        0            0       0\n",
       "2  T00001_S003           1           0        0        0            0       0\n",
       "3  T00001_S004           0           1        0        0            0       0\n",
       "4  T00001_S005           0           0        0        1            0       0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_submission.to_csv('test_submission.csv', index=False)\n",
    "test_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {1: 130879, 2: 287})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "d = defaultdict(int)\n",
    "\n",
    "for i, p in enumerate(y_pred):\n",
    "    categories = p.split('/')\n",
    "    l = len(categories)\n",
    "    \n",
    "    d[l] += 1\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue for Naive Bayes Classifier\n",
    "Hard to classify multi-class data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
