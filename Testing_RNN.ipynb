{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic libraries import\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from gensim.models import KeyedVectors\n",
    "import helpers.data_mining_helpers as dmh\n",
    "from scipy.sparse import csr_matrix, vstack, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk library\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn library\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# keras library\n",
    "# preprocess\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# model\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input, Embedding\n",
    "from keras.layers import ReLU, Softmax\n",
    "from keras.callbacks import Callback\n",
    "# RNN\n",
    "from keras.layers import Dropout, LSTM, Bidirectional, CuDNNLSTM, CuDNNGRU\n",
    "# CNN\n",
    "from keras.layers import GlobalMaxPooling1D, GlobalMaxPool1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Concatenate\n",
    "# load model\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plz setting your own relative data_path for trainning set\n",
    "# plz import the necessary file by your own\n",
    "# or just comment out the part you don't need to import\n",
    "dir_data = 'data'\n",
    "\n",
    "f_train_df = os.path.join(dir_data, 'train_df.pkl')\n",
    "f_test_df = os.path.join(dir_data, 'test_df.pkl')\n",
    "f_public_test_df = os.path.join(dir_data, 'public_test_df.pkl')\n",
    "f_test_submission = os.path.join(dir_data, 'task1_sample_submission.csv')\n",
    "\n",
    "# read file and convert into pandas dataframe\n",
    "train_df = pd.read_pickle(f_train_df)\n",
    "test_df = pd.read_pickle(f_test_df)\n",
    "public_test_df = pd.read_pickle(f_public_test_df)\n",
    "test_submission = pd.read_csv(f_test_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "def label_decode(le, vec):\n",
    "    dec = np.where(vec > 0.5, 1, 0)\n",
    "    return dec\n",
    "#     dec = np.argmax(one_hot_label, axis=1)\n",
    "#     return le.inverse_transform(dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_logger\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('logs/training_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# micro f1 score metrics\n",
    "class Metrics(Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.val_f1s = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = self.model.predict(self.validation_data[0])\n",
    "        y_pred = label_decode(label_encoder, y_pred)\n",
    "        y_true = label_decode(label_encoder, self.validation_data[1])\n",
    "        _val_f1 = f1_score(y_true, y_pred, average='micro')\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        print(classification_report(y_true=y_true, y_pred=y_pred))\n",
    "        print(_val_f1)\n",
    "    \n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label'] = train_df['Task'].apply(lambda t : t.split('/'))\n",
    "test_df['label'] = test_df['Task'].apply(lambda t : t.split('/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sentence preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Task</th>\n",
       "      <th>Doc_no.</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Rank%</th>\n",
       "      <th>Num_of_sentences</th>\n",
       "      <th>Is_first</th>\n",
       "      <th>Is_last</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>While service-dominant logic proposes that all...</td>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>5848</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[BACKGROUND]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three longitudinal case studies in B2B equipme...</td>\n",
       "      <td>OBJECTIVES</td>\n",
       "      <td>5848</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[OBJECTIVES]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We found the nature of value, degree of contex...</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>5848</td>\n",
       "      <td>2</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[METHODS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To counter this, the firm uses (a) Direct Serv...</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>5848</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[METHODS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The co-creation of complex multidimensional va...</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>5848</td>\n",
       "      <td>4</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[METHODS]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence        Task  Doc_no.  \\\n",
       "0  While service-dominant logic proposes that all...  BACKGROUND     5848   \n",
       "1  Three longitudinal case studies in B2B equipme...  OBJECTIVES     5848   \n",
       "2  We found the nature of value, degree of contex...     METHODS     5848   \n",
       "3  To counter this, the firm uses (a) Direct Serv...     METHODS     5848   \n",
       "4  The co-creation of complex multidimensional va...     METHODS     5848   \n",
       "\n",
       "   Rank     Rank%  Num_of_sentences  Is_first  Is_last         label  \n",
       "0     0  0.000000                 9         1        0  [BACKGROUND]  \n",
       "1     1  0.111111                 9         0        0  [OBJECTIVES]  \n",
       "2     2  0.222222                 9         0        0     [METHODS]  \n",
       "3     3  0.333333                 9         0        0     [METHODS]  \n",
       "4     4  0.444444                 9         0        0     [METHODS]  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~' + \"“”\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_convert_dict = dmh.term_convert_dict_easy\n",
    "stopwords = dmh.stop_word_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;#+_]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z ]')\n",
    "TRANSLATOR = str.maketrans(punctuation, ' ' * len(punctuation))\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "#     tokens = nltk.word_tokenize(text)\n",
    "#     tokens = [w for w in tokens if not w in stopwords] \n",
    "#     text = ' '.join(tokens)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_preprocess(df):\n",
    "    # text preprocess   \n",
    "    df['p_text'] = df['Sentence'].apply(clean_text)\n",
    "#     df['p_text'] = df['p_text'].str.replace('\\d+', '')\n",
    "    df['tmp'] = df['p_text'].apply(lambda s : nltk.word_tokenize(s))\n",
    "\n",
    "    # replace common terms with words in pre-trained model\n",
    "    df['tmp'] = df['tmp'].apply(lambda u : [term_convert_dict[w] if w in term_convert_dict else w for w in u])\n",
    "\n",
    "    df['p_text'] = df['tmp'].apply(lambda a : ' '.join(a))\n",
    "    \n",
    "    df.drop(['tmp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 5.345385313034058 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "df_preprocess(train_df)\n",
    "train_df.head()\n",
    "\n",
    "print(f'time : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Task</th>\n",
       "      <th>Doc_no.</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Rank%</th>\n",
       "      <th>Num_of_sentences</th>\n",
       "      <th>Is_first</th>\n",
       "      <th>Is_last</th>\n",
       "      <th>label</th>\n",
       "      <th>p_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>While service-dominant logic proposes that all...</td>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>5848</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[BACKGROUND]</td>\n",
       "      <td>while service-dominant logic proposes that all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three longitudinal case studies in B2B equipme...</td>\n",
       "      <td>OBJECTIVES</td>\n",
       "      <td>5848</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[OBJECTIVES]</td>\n",
       "      <td>three longitudinal case studies in b2b equipme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We found the nature of value, degree of contex...</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>5848</td>\n",
       "      <td>2</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[METHODS]</td>\n",
       "      <td>we found the nature of value , degree of conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To counter this, the firm uses (a) Direct Serv...</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>5848</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[METHODS]</td>\n",
       "      <td>to counter this , the firm uses ( a ) direct s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The co-creation of complex multidimensional va...</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>5848</td>\n",
       "      <td>4</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[METHODS]</td>\n",
       "      <td>the co-creation of complex multidimensional va...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence        Task  Doc_no.  \\\n",
       "0  While service-dominant logic proposes that all...  BACKGROUND     5848   \n",
       "1  Three longitudinal case studies in B2B equipme...  OBJECTIVES     5848   \n",
       "2  We found the nature of value, degree of contex...     METHODS     5848   \n",
       "3  To counter this, the firm uses (a) Direct Serv...     METHODS     5848   \n",
       "4  The co-creation of complex multidimensional va...     METHODS     5848   \n",
       "\n",
       "   Rank     Rank%  Num_of_sentences  Is_first  Is_last         label  \\\n",
       "0     0  0.000000                 9         1        0  [BACKGROUND]   \n",
       "1     1  0.111111                 9         0        0  [OBJECTIVES]   \n",
       "2     2  0.222222                 9         0        0     [METHODS]   \n",
       "3     3  0.333333                 9         0        0     [METHODS]   \n",
       "4     4  0.444444                 9         0        0     [METHODS]   \n",
       "\n",
       "                                              p_text  \n",
       "0  while service-dominant logic proposes that all...  \n",
       "1  three longitudinal case studies in b2b equipme...  \n",
       "2  we found the nature of value , degree of conte...  \n",
       "3  to counter this , the firm uses ( a ) direct s...  \n",
       "4  the co-creation of complex multidimensional va...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Task</th>\n",
       "      <th>Doc_no.</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Rank%</th>\n",
       "      <th>Num_of_sentences</th>\n",
       "      <th>Is_first</th>\n",
       "      <th>Is_last</th>\n",
       "      <th>label</th>\n",
       "      <th>p_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We propose a new stochastic L-BFGS algorithm a...</td>\n",
       "      <td>OBJECTIVES</td>\n",
       "      <td>1376</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[OBJECTIVES]</td>\n",
       "      <td>we propose a new stochastic l-bfgs algorithm a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our algorithm draws heavily from a recent stoc...</td>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>1376</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[BACKGROUND]</td>\n",
       "      <td>our algorithm draws heavily from a recent stoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2014) as well as a recent approach to varianc...</td>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>1376</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[BACKGROUND]</td>\n",
       "      <td>( 2014 ) as well as a recent approach to varia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We demonstrate experimentally that our algorit...</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>1376</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[RESULTS]</td>\n",
       "      <td>we demonstrate experimentally that our algorit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Furthermore, we show that our algorithm perfor...</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>1376</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[RESULTS]</td>\n",
       "      <td>furthermore , we show that our algorithm perfo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence        Task  Doc_no.  \\\n",
       "0  We propose a new stochastic L-BFGS algorithm a...  OBJECTIVES     1376   \n",
       "1  Our algorithm draws heavily from a recent stoc...  BACKGROUND     1376   \n",
       "2  (2014) as well as a recent approach to varianc...  BACKGROUND     1376   \n",
       "3  We demonstrate experimentally that our algorit...     RESULTS     1376   \n",
       "4  Furthermore, we show that our algorithm perfor...     RESULTS     1376   \n",
       "\n",
       "   Rank  Rank%  Num_of_sentences  Is_first  Is_last         label  \\\n",
       "0     0    0.0                 5         1        0  [OBJECTIVES]   \n",
       "1     1    0.2                 5         0        0  [BACKGROUND]   \n",
       "2     2    0.4                 5         0        0  [BACKGROUND]   \n",
       "3     3    0.6                 5         0        0     [RESULTS]   \n",
       "4     4    0.8                 5         0        1     [RESULTS]   \n",
       "\n",
       "                                              p_text  \n",
       "0  we propose a new stochastic l-bfgs algorithm a...  \n",
       "1  our algorithm draws heavily from a recent stoc...  \n",
       "2  ( 2014 ) as well as a recent approach to varia...  \n",
       "3  we demonstrate experimentally that our algorit...  \n",
       "4  furthermore , we show that our algorithm perfo...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocess(test_df)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9316"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 18.351952075958252 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "df_preprocess(test_df)\n",
    "df_preprocess(public_test_df)\n",
    "\n",
    "print(f'time : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Task</th>\n",
       "      <th>Doc_no.</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Rank%</th>\n",
       "      <th>Num_of_sentences</th>\n",
       "      <th>Is_first</th>\n",
       "      <th>Is_last</th>\n",
       "      <th>label</th>\n",
       "      <th>p_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We propose a new stochastic L-BFGS algorithm a...</td>\n",
       "      <td>OBJECTIVES</td>\n",
       "      <td>1376</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[OBJECTIVES]</td>\n",
       "      <td>we propose a new stochastic l-bfgs algorithm a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our algorithm draws heavily from a recent stoc...</td>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>1376</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[BACKGROUND]</td>\n",
       "      <td>our algorithm draws heavily from a recent stoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2014) as well as a recent approach to varianc...</td>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>1376</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[BACKGROUND]</td>\n",
       "      <td>( 2014 ) as well as a recent approach to varia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We demonstrate experimentally that our algorit...</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>1376</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[RESULTS]</td>\n",
       "      <td>we demonstrate experimentally that our algorit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Furthermore, we show that our algorithm perfor...</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>1376</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[RESULTS]</td>\n",
       "      <td>furthermore , we show that our algorithm perfo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence        Task  Doc_no.  \\\n",
       "0  We propose a new stochastic L-BFGS algorithm a...  OBJECTIVES     1376   \n",
       "1  Our algorithm draws heavily from a recent stoc...  BACKGROUND     1376   \n",
       "2  (2014) as well as a recent approach to varianc...  BACKGROUND     1376   \n",
       "3  We demonstrate experimentally that our algorit...     RESULTS     1376   \n",
       "4  Furthermore, we show that our algorithm perfor...     RESULTS     1376   \n",
       "\n",
       "   Rank  Rank%  Num_of_sentences  Is_first  Is_last         label  \\\n",
       "0     0    0.0                 5         1        0  [OBJECTIVES]   \n",
       "1     1    0.2                 5         0        0  [BACKGROUND]   \n",
       "2     2    0.4                 5         0        0  [BACKGROUND]   \n",
       "3     3    0.6                 5         0        0     [RESULTS]   \n",
       "4     4    0.8                 5         0        1     [RESULTS]   \n",
       "\n",
       "                                              p_text  \n",
       "0  we propose a new stochastic l-bfgs algorithm a...  \n",
       "1  our algorithm draws heavily from a recent stoc...  \n",
       "2  ( 2014 ) as well as a recent approach to varia...  \n",
       "3  we demonstrate experimentally that our algorit...  \n",
       "4  furthermore , we show that our algorithm perfo...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load pre-train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ok\n"
     ]
    }
   ],
   "source": [
    "# GoogleNews\n",
    "model_path = \"data/GoogleNews-vectors-negative300.bin.gz\"\n",
    "w2v_google_model = KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "\n",
    "print('load ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ok\n"
     ]
    }
   ],
   "source": [
    "# GloVe Wikipedia 2014 + Gigaword 5\n",
    "model_path = \"data/glove.6B/word2vec.6B.300d.txt\"\n",
    "w2v_glove_wiki_300_model = KeyedVectors.load_word2vec_format(model_path, binary=False)\n",
    "\n",
    "print('load ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ok\n"
     ]
    }
   ],
   "source": [
    "# GloVe Common Crawl\n",
    "model_path = \"data/glove.42B/word2vec.42B.300d.txt\"\n",
    "w2v_glove_300_model = KeyedVectors.load_word2vec_format(model_path, binary=False)\n",
    "\n",
    "print('load ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter out OTHERS/CONCLUSION sentences & outlier sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BACKGROUND', 'METHODS', 'RESULTS', 'OBJECTIVES', 'CONCLUSIONS',\n",
       "       'RESULTS/CONCLUSIONS', 'OBJECTIVES/METHODS', 'METHODS/RESULTS',\n",
       "       'BACKGROUND/OBJECTIVES', 'OTHERS', 'OBJECTIVES/RESULTS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = train_df['Task'].value_counts()\n",
    "s = s[s / len(train_df) * 100 > 0.5]\n",
    "s.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36608"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = train_df['Task'].apply(lambda t : t in s.index)\n",
    "train_df = train_df[f]\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN train data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df\n",
    "word_model = w2v_glove_300_model\n",
    "# word_model = w2v_glove_wiki_200_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 5000\n",
    "MAX_LENGTH = 60\n",
    "EMBEDDING_DIM = word_model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32938 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters=\"\", lower=True)\n",
    "tokenizer.fit_on_texts(df['p_text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " '.': 2,\n",
       " ',': 3,\n",
       " 'of': 4,\n",
       " 'and': 5,\n",
       " 'a': 6,\n",
       " 'to': 7,\n",
       " 'in': 8,\n",
       " 'we': 9,\n",
       " 'is': 10,\n",
       " 'for': 11,\n",
       " 'that': 12,\n",
       " 'on': 13,\n",
       " ')': 14,\n",
       " 'this': 15,\n",
       " '(': 16,\n",
       " 'with': 17,\n",
       " 'are': 18,\n",
       " 'as': 19,\n",
       " 'by': 20,\n",
       " 'an': 21,\n",
       " 'our': 22,\n",
       " 'data': 23,\n",
       " 'from': 24,\n",
       " 'can': 25,\n",
       " 'be': 26,\n",
       " 'which': 27,\n",
       " 'model': 28,\n",
       " 'network': 29,\n",
       " 'paper': 30,\n",
       " 'it': 31,\n",
       " 'using': 32,\n",
       " 'learning': 33,\n",
       " 'results': 34,\n",
       " 'based': 35,\n",
       " 'such': 36,\n",
       " 'proposed': 37,\n",
       " 'or': 38,\n",
       " 'show': 39,\n",
       " 'problem': 40,\n",
       " 'have': 41,\n",
       " 'method': 42,\n",
       " 'these': 43,\n",
       " 'algorithm': 44,\n",
       " 'performance': 45,\n",
       " 'networks': 46,\n",
       " 'approach': 47,\n",
       " 'has': 48,\n",
       " 'also': 49,\n",
       " 'not': 50,\n",
       " 'at': 51,\n",
       " 'information': 52,\n",
       " 'system': 53,\n",
       " 'methods': 54,\n",
       " 'propose': 55,\n",
       " 'used': 56,\n",
       " 'models': 57,\n",
       " 'different': 58,\n",
       " 'their': 59,\n",
       " 'two': 60,\n",
       " 'neural': 61,\n",
       " 'new': 62,\n",
       " 'between': 63,\n",
       " 'time': 64,\n",
       " 'more': 65,\n",
       " 'use': 66,\n",
       " 'systems': 67,\n",
       " 'its': 68,\n",
       " 'one': 69,\n",
       " 'both': 70,\n",
       " 'been': 71,\n",
       " 'analysis': 72,\n",
       " 'algorithms': 73,\n",
       " 'image': 74,\n",
       " 'each': 75,\n",
       " ':': 76,\n",
       " 'present': 77,\n",
       " 'work': 78,\n",
       " 'number': 79,\n",
       " 'over': 80,\n",
       " 'deep': 81,\n",
       " 'framework': 82,\n",
       " 'however': 83,\n",
       " 'other': 84,\n",
       " 'when': 85,\n",
       " 'set': 86,\n",
       " 'into': 87,\n",
       " 'training': 88,\n",
       " 'study': 89,\n",
       " \"'s\": 90,\n",
       " 'but': 91,\n",
       " 'features': 92,\n",
       " 'only': 93,\n",
       " 'than': 94,\n",
       " 'while': 95,\n",
       " 'all': 96,\n",
       " 'where': 97,\n",
       " 'first': 98,\n",
       " 'how': 99,\n",
       " 'novel': 100,\n",
       " 'most': 101,\n",
       " 'dataset': 102,\n",
       " 'large': 103,\n",
       " 'many': 104,\n",
       " 'applications': 105,\n",
       " 'images': 106,\n",
       " 'task': 107,\n",
       " 'provide': 108,\n",
       " 'well': 109,\n",
       " '%': 110,\n",
       " 'research': 111,\n",
       " 'problems': 112,\n",
       " 'design': 113,\n",
       " 'demonstrate': 114,\n",
       " 'experiments': 115,\n",
       " 'then': 116,\n",
       " 'classification': 117,\n",
       " 'detection': 118,\n",
       " 'datasets': 119,\n",
       " 'some': 120,\n",
       " 'users': 121,\n",
       " 'existing': 122,\n",
       " 'process': 123,\n",
       " 'they': 124,\n",
       " 'several': 125,\n",
       " 'through': 126,\n",
       " 'state-of-the-art': 127,\n",
       " 'accuracy': 128,\n",
       " 'tasks': 129,\n",
       " 'techniques': 130,\n",
       " 'approaches': 131,\n",
       " 'high': 132,\n",
       " 'order': 133,\n",
       " 'graph': 134,\n",
       " 'space': 135,\n",
       " 'function': 136,\n",
       " 'given': 137,\n",
       " 'control': 138,\n",
       " 'knowledge': 139,\n",
       " 'human': 140,\n",
       " 'multiple': 141,\n",
       " 'user': 142,\n",
       " 'machine': 143,\n",
       " 'important': 144,\n",
       " 'structure': 145,\n",
       " 'language': 146,\n",
       " 'various': 147,\n",
       " 'recognition': 148,\n",
       " 'better': 149,\n",
       " 'may': 150,\n",
       " '``': 151,\n",
       " ';': 152,\n",
       " 'there': 153,\n",
       " 'social': 154,\n",
       " \"''\": 155,\n",
       " 'efficient': 156,\n",
       " 'compared': 157,\n",
       " 'optimization': 158,\n",
       " 'optimal': 159,\n",
       " 'any': 160,\n",
       " 'due': 161,\n",
       " 'linear': 162,\n",
       " 'under': 163,\n",
       " 'case': 164,\n",
       " 'them': 165,\n",
       " 'quality': 166,\n",
       " 'state': 167,\n",
       " 'recent': 168,\n",
       " 'available': 169,\n",
       " 'simple': 170,\n",
       " 'input': 171,\n",
       " 'local': 172,\n",
       " 'without': 173,\n",
       " 'feature': 174,\n",
       " 'solution': 175,\n",
       " 'power': 176,\n",
       " 'complex': 177,\n",
       " 'very': 178,\n",
       " 'introduce': 179,\n",
       " 'representation': 180,\n",
       " 'general': 181,\n",
       " 'real': 182,\n",
       " 'was': 183,\n",
       " 'about': 184,\n",
       " 'object': 185,\n",
       " 'software': 186,\n",
       " 'convolutional': 187,\n",
       " 'same': 188,\n",
       " 'communication': 189,\n",
       " 'three': 190,\n",
       " 'further': 191,\n",
       " \"'\": 192,\n",
       " 'will': 193,\n",
       " 'complexity': 194,\n",
       " 'prediction': 195,\n",
       " 'improve': 196,\n",
       " 'rate': 197,\n",
       " 'particular': 198,\n",
       " 'technique': 199,\n",
       " 'evaluation': 200,\n",
       " 'experimental': 201,\n",
       " 'estimation': 202,\n",
       " 'properties': 203,\n",
       " 'computational': 204,\n",
       " 'processing': 205,\n",
       " 'energy': 206,\n",
       " 'error': 207,\n",
       " 'single': 208,\n",
       " 'find': 209,\n",
       " 'application': 210,\n",
       " 'provides': 211,\n",
       " 'domain': 212,\n",
       " 'terms': 213,\n",
       " 'distribution': 214,\n",
       " 'often': 215,\n",
       " 'allows': 216,\n",
       " 'architecture': 217,\n",
       " 'functions': 218,\n",
       " 'possible': 219,\n",
       " 'search': 220,\n",
       " 'semantic': 221,\n",
       " 'random': 222,\n",
       " 'code': 223,\n",
       " 'key': 224,\n",
       " 'current': 225,\n",
       " 'parameters': 226,\n",
       " 'learn': 227,\n",
       " 'even': 228,\n",
       " 'thus': 229,\n",
       " 'online': 230,\n",
       " 'scheme': 231,\n",
       " 'context': 232,\n",
       " 'segmentation': 233,\n",
       " 'applied': 234,\n",
       " 'way': 235,\n",
       " 'source': 236,\n",
       " 'distributed': 237,\n",
       " 'dynamic': 238,\n",
       " 'memory': 239,\n",
       " 'achieve': 240,\n",
       " 'including': 241,\n",
       " 'were': 242,\n",
       " 'standard': 243,\n",
       " 'among': 244,\n",
       " 'video': 245,\n",
       " 'visual': 246,\n",
       " 'evaluate': 247,\n",
       " 'class': 248,\n",
       " 'finally': 249,\n",
       " 'if': 250,\n",
       " 'previous': 251,\n",
       " 'small': 252,\n",
       " 'computing': 253,\n",
       " 'within': 254,\n",
       " 'objects': 255,\n",
       " 'consider': 256,\n",
       " 'best': 257,\n",
       " 'channel': 258,\n",
       " 'trained': 259,\n",
       " 'result': 260,\n",
       " 'shown': 261,\n",
       " 'size': 262,\n",
       " 'obtained': 263,\n",
       " 'test': 264,\n",
       " 'challenging': 265,\n",
       " 'called': 266,\n",
       " 'level': 267,\n",
       " 'no': 268,\n",
       " 'cost': 269,\n",
       " 'able': 270,\n",
       " 'significant': 271,\n",
       " 'text': 272,\n",
       " 'up': 273,\n",
       " 'so': 274,\n",
       " 'nodes': 275,\n",
       " 'natural': 276,\n",
       " 'perform': 277,\n",
       " '3d': 278,\n",
       " 'development': 279,\n",
       " 'simulation': 280,\n",
       " 'known': 281,\n",
       " 'temporal': 282,\n",
       " 'effective': 283,\n",
       " 'target': 284,\n",
       " 'modeling': 285,\n",
       " 'graphs': 286,\n",
       " 'efficiency': 287,\n",
       " 'conditions': 288,\n",
       " 'theory': 289,\n",
       " 'behavior': 290,\n",
       " 'make': 291,\n",
       " 'signal': 292,\n",
       " 'support': 293,\n",
       " 'access': 294,\n",
       " 'global': 295,\n",
       " 'presents': 296,\n",
       " 'implementation': 297,\n",
       " 'significantly': 298,\n",
       " 'studies': 299,\n",
       " 'developed': 300,\n",
       " 'representations': 301,\n",
       " 'during': 302,\n",
       " 'specific': 303,\n",
       " 'environment': 304,\n",
       " 'constraints': 305,\n",
       " 'recently': 306,\n",
       " 'address': 307,\n",
       " 'probability': 308,\n",
       " 'sequence': 309,\n",
       " 'matrix': 310,\n",
       " 'word': 311,\n",
       " 'computer': 312,\n",
       " 'common': 313,\n",
       " 'across': 314,\n",
       " 'develop': 315,\n",
       " 'computation': 316,\n",
       " 'effectiveness': 317,\n",
       " 'point': 318,\n",
       " 'dynamics': 319,\n",
       " 'via': 320,\n",
       " 'need': 321,\n",
       " 'solutions': 322,\n",
       " 'robust': 323,\n",
       " 'main': 324,\n",
       " 'do': 325,\n",
       " 'sets': 326,\n",
       " 'loss': 327,\n",
       " 'attention': 328,\n",
       " 'identify': 329,\n",
       " 'low': 330,\n",
       " 'potential': 331,\n",
       " 'considered': 332,\n",
       " 'outperforms': 333,\n",
       " 'second': 334,\n",
       " 'presented': 335,\n",
       " 'being': 336,\n",
       " 'furthermore': 337,\n",
       " 'content': 338,\n",
       " 'similar': 339,\n",
       " 'noise': 340,\n",
       " 'form': 341,\n",
       " 'those': 342,\n",
       " 'real-world': 343,\n",
       " 'lower': 344,\n",
       " 'field': 345,\n",
       " 'cnn': 346,\n",
       " 'future': 347,\n",
       " '--': 348,\n",
       " 'analyze': 349,\n",
       " 'patterns': 350,\n",
       " 'like': 351,\n",
       " 'since': 352,\n",
       " 'limited': 353,\n",
       " 'literature': 354,\n",
       " 'much': 355,\n",
       " 'related': 356,\n",
       " 'challenges': 357,\n",
       " 'inference': 358,\n",
       " 'generate': 359,\n",
       " 'obtain': 360,\n",
       " 'generated': 361,\n",
       " 'mobile': 362,\n",
       " 'uses': 363,\n",
       " 'here': 364,\n",
       " 'strategy': 365,\n",
       " 'types': 366,\n",
       " 'out': 367,\n",
       " 'clustering': 368,\n",
       " 'traditional': 369,\n",
       " 'spatial': 370,\n",
       " 'measures': 371,\n",
       " 'achieves': 372,\n",
       " 'benchmark': 373,\n",
       " 'samples': 374,\n",
       " 'cases': 375,\n",
       " 'theoretical': 376,\n",
       " 'numerical': 377,\n",
       " 'therefore': 378,\n",
       " 'us': 379,\n",
       " 'service': 380,\n",
       " 'designed': 381,\n",
       " 'robot': 382,\n",
       " 'output': 383,\n",
       " 'objective': 384,\n",
       " 'good': 385,\n",
       " 'tools': 386,\n",
       " 'examples': 387,\n",
       " 'specifically': 388,\n",
       " 'understanding': 389,\n",
       " 'security': 390,\n",
       " 'range': 391,\n",
       " 'addition': 392,\n",
       " 'query': 393,\n",
       " 'vector': 394,\n",
       " 'prove': 395,\n",
       " 'does': 396,\n",
       " 'agents': 397,\n",
       " 'sparse': 398,\n",
       " 'solve': 399,\n",
       " 'higher': 400,\n",
       " 'sampling': 401,\n",
       " 'generation': 402,\n",
       " 'because': 403,\n",
       " 'individual': 404,\n",
       " 'shows': 405,\n",
       " 'requires': 406,\n",
       " 'popular': 407,\n",
       " 'programming': 408,\n",
       " 'devices': 409,\n",
       " 'structures': 410,\n",
       " 'selection': 411,\n",
       " 'type': 412,\n",
       " 'wireless': 413,\n",
       " 'strategies': 414,\n",
       " 'impact': 415,\n",
       " 'traffic': 416,\n",
       " 'describe': 417,\n",
       " 'translation': 418,\n",
       " 'statistical': 419,\n",
       " 'practical': 420,\n",
       " 'cloud': 421,\n",
       " 'against': 422,\n",
       " 'web': 423,\n",
       " 'accurate': 424,\n",
       " 'still': 425,\n",
       " 'could': 426,\n",
       " '1': 427,\n",
       " 'world': 428,\n",
       " 'similarity': 429,\n",
       " 'years': 430,\n",
       " 'achieved': 431,\n",
       " 'value': 432,\n",
       " 'investigate': 433,\n",
       " 'learned': 434,\n",
       " 'moreover': 435,\n",
       " 'policy': 436,\n",
       " 'motion': 437,\n",
       " 'found': 438,\n",
       " 'focus': 439,\n",
       " 'face': 440,\n",
       " 'decision': 441,\n",
       " 'i.e.': 442,\n",
       " 'average': 443,\n",
       " 'tool': 444,\n",
       " 'challenge': 445,\n",
       " 'speech': 446,\n",
       " 'mechanism': 447,\n",
       " 'generative': 448,\n",
       " '2': 449,\n",
       " 'architectures': 450,\n",
       " 'useful': 451,\n",
       " 'example': 452,\n",
       " '-': 453,\n",
       " 'measure': 454,\n",
       " 'original': 455,\n",
       " 'words': 456,\n",
       " 'extensive': 457,\n",
       " 'open': 458,\n",
       " 'highly': 459,\n",
       " 'quantum': 460,\n",
       " 'bound': 461,\n",
       " 'fast': 462,\n",
       " 'large-scale': 463,\n",
       " 'resources': 464,\n",
       " 'classes': 465,\n",
       " 'part': 466,\n",
       " 'game': 467,\n",
       " 'reduce': 468,\n",
       " 'few': 469,\n",
       " 'distance': 470,\n",
       " 'scale': 471,\n",
       " 'scenarios': 472,\n",
       " 'estimate': 473,\n",
       " 'compare': 474,\n",
       " 'services': 475,\n",
       " 'area': 476,\n",
       " 'interest': 477,\n",
       " 'require': 478,\n",
       " 'automatic': 479,\n",
       " 'difficult': 480,\n",
       " 'evaluated': 481,\n",
       " 'increase': 482,\n",
       " 'adversarial': 483,\n",
       " 'points': 484,\n",
       " 'map': 485,\n",
       " 'should': 486,\n",
       " 'directly': 487,\n",
       " 'embedding': 488,\n",
       " 'predict': 489,\n",
       " 'recurrent': 490,\n",
       " 'domains': 491,\n",
       " 'what': 492,\n",
       " 'simulations': 493,\n",
       " 'bounds': 494,\n",
       " 'certain': 495,\n",
       " 'automatically': 496,\n",
       " 'community': 497,\n",
       " 'group': 498,\n",
       " 'metrics': 499,\n",
       " 'tracking': 500,\n",
       " 'values': 501,\n",
       " 'goal': 502,\n",
       " 'provided': 503,\n",
       " 'give': 504,\n",
       " 'classical': 505,\n",
       " 'flow': 506,\n",
       " 'less': 507,\n",
       " 'associated': 508,\n",
       " 'makes': 509,\n",
       " 'layer': 510,\n",
       " 'resulting': 511,\n",
       " 'management': 512,\n",
       " 'processes': 513,\n",
       " 'efficiently': 514,\n",
       " 'either': 515,\n",
       " 'long': 516,\n",
       " 'finite': 517,\n",
       " 'physical': 518,\n",
       " 'supervised': 519,\n",
       " 'regression': 520,\n",
       " 'ability': 521,\n",
       " 'empirical': 522,\n",
       " 'technology': 523,\n",
       " 'stochastic': 524,\n",
       " 'capture': 525,\n",
       " 'apply': 526,\n",
       " 'setting': 527,\n",
       " 'capacity': 528,\n",
       " 'after': 529,\n",
       " 'signals': 530,\n",
       " 'transfer': 531,\n",
       " 'codes': 532,\n",
       " 'languages': 533,\n",
       " 'sensor': 534,\n",
       " 'discuss': 535,\n",
       " 'relevant': 536,\n",
       " 'database': 537,\n",
       " 'states': 538,\n",
       " 'vision': 539,\n",
       " 'attacks': 540,\n",
       " 'variety': 541,\n",
       " 'conventional': 542,\n",
       " 'variables': 543,\n",
       " 'concept': 544,\n",
       " 'effect': 545,\n",
       " 'prior': 546,\n",
       " 'scientific': 547,\n",
       " 'issues': 548,\n",
       " 'implemented': 549,\n",
       " 'series': 550,\n",
       " 'increasing': 551,\n",
       " 'maximum': 552,\n",
       " 'sequences': 553,\n",
       " 'amount': 554,\n",
       " 'train': 555,\n",
       " 'depth': 556,\n",
       " 'whether': 557,\n",
       " 'characteristics': 558,\n",
       " 'improved': 559,\n",
       " 'corresponding': 560,\n",
       " 'unsupervised': 561,\n",
       " 'works': 562,\n",
       " 'discrete': 563,\n",
       " 'view': 564,\n",
       " 'step': 565,\n",
       " 'interaction': 566,\n",
       " 'continuous': 567,\n",
       " 'testing': 568,\n",
       " 'performed': 569,\n",
       " 'along': 570,\n",
       " 'required': 571,\n",
       " 'underlying': 572,\n",
       " 'parallel': 573,\n",
       " 'introduced': 574,\n",
       " 'derive': 575,\n",
       " 'probabilistic': 576,\n",
       " 'help': 577,\n",
       " 'requirements': 578,\n",
       " 'path': 579,\n",
       " 'reduction': 580,\n",
       " 'approximation': 581,\n",
       " 'latent': 582,\n",
       " 'gradient': 583,\n",
       " 'e.g.': 584,\n",
       " 'additional': 585,\n",
       " 'observed': 586,\n",
       " 'schemes': 587,\n",
       " 'resource': 588,\n",
       " 'improvement': 589,\n",
       " 'critical': 590,\n",
       " 'comparison': 591,\n",
       " 'matching': 592,\n",
       " 'enables': 593,\n",
       " 'researchers': 594,\n",
       " 'labels': 595,\n",
       " 'transmission': 596,\n",
       " 'metric': 597,\n",
       " 'issue': 598,\n",
       " 'frequency': 599,\n",
       " 'agent': 600,\n",
       " 'become': 601,\n",
       " 'defined': 602,\n",
       " 'program': 603,\n",
       " 'science': 604,\n",
       " 'yet': 605,\n",
       " 'wide': 606,\n",
       " 'logic': 607,\n",
       " 'major': 608,\n",
       " 'planning': 609,\n",
       " 'practice': 610,\n",
       " 'especially': 611,\n",
       " 'end-to-end': 612,\n",
       " 'widely': 613,\n",
       " 'fully': 614,\n",
       " 'synthetic': 615,\n",
       " 'article': 616,\n",
       " 'sources': 617,\n",
       " 'layers': 618,\n",
       " 'node': 619,\n",
       " 'effectively': 620,\n",
       " 'active': 621,\n",
       " 'feedback': 622,\n",
       " 'queries': 623,\n",
       " 'interference': 624,\n",
       " 'robustness': 625,\n",
       " 'detect': 626,\n",
       " 'times': 627,\n",
       " 'i': 628,\n",
       " 'reconstruction': 629,\n",
       " 'making': 630,\n",
       " 'strong': 631,\n",
       " 'events': 632,\n",
       " 'factors': 633,\n",
       " 'components': 634,\n",
       " 'change': 635,\n",
       " 'distributions': 636,\n",
       " 'importance': 637,\n",
       " 'action': 638,\n",
       " 'usually': 639,\n",
       " 'operations': 640,\n",
       " 'joint': 641,\n",
       " 'procedure': 642,\n",
       " 'environments': 643,\n",
       " 'rules': 644,\n",
       " 'end': 645,\n",
       " 'identification': 646,\n",
       " 'derived': 647,\n",
       " 'degree': 648,\n",
       " 'finding': 649,\n",
       " 'hybrid': 650,\n",
       " 'explore': 651,\n",
       " 'phase': 652,\n",
       " 'respect': 653,\n",
       " 'relations': 654,\n",
       " 'hardware': 655,\n",
       " 'faster': 656,\n",
       " 'classifier': 657,\n",
       " 'according': 658,\n",
       " 'reinforcement': 659,\n",
       " 'pose': 660,\n",
       " 'speed': 661,\n",
       " 'public': 662,\n",
       " 'artificial': 663,\n",
       " 'execution': 664,\n",
       " 'convergence': 665,\n",
       " 'medical': 666,\n",
       " 'interactions': 667,\n",
       " 'component': 668,\n",
       " 'four': 669,\n",
       " 'role': 670,\n",
       " 'necessary': 671,\n",
       " 'nature': 672,\n",
       " 'privacy': 673,\n",
       " 'sample': 674,\n",
       " 'represent': 675,\n",
       " 'building': 676,\n",
       " 'instead': 677,\n",
       " 'combination': 678,\n",
       " 'fundamental': 679,\n",
       " 'sensing': 680,\n",
       " 'nonlinear': 681,\n",
       " 'weights': 682,\n",
       " 'solving': 683,\n",
       " 'towards': 684,\n",
       " 'providing': 685,\n",
       " 'regions': 686,\n",
       " 'filter': 687,\n",
       " 'promising': 688,\n",
       " 'changes': 689,\n",
       " 'leads': 690,\n",
       " 'considering': 691,\n",
       " 'allow': 692,\n",
       " 'improves': 693,\n",
       " 'measurements': 694,\n",
       " 'basic': 695,\n",
       " 'instances': 696,\n",
       " 'produce': 697,\n",
       " 'overall': 698,\n",
       " 'basis': 699,\n",
       " 'media': 700,\n",
       " 'studied': 701,\n",
       " 'means': 702,\n",
       " 'activity': 703,\n",
       " 'expected': 704,\n",
       " 'influence': 705,\n",
       " 'aspects': 706,\n",
       " 'question': 707,\n",
       " 'correlation': 708,\n",
       " 'account': 709,\n",
       " 'actions': 710,\n",
       " 'grid': 711,\n",
       " 'respectively': 712,\n",
       " 'collected': 713,\n",
       " 'digital': 714,\n",
       " 'binary': 715,\n",
       " 'protocol': 716,\n",
       " 'demonstrated': 717,\n",
       " 'hand': 718,\n",
       " 'games': 719,\n",
       " 'adaptive': 720,\n",
       " '?': 721,\n",
       " 'coding': 722,\n",
       " 'rates': 723,\n",
       " 'aim': 724,\n",
       " 'although': 725,\n",
       " 'technologies': 726,\n",
       " 'initial': 727,\n",
       " 'review': 728,\n",
       " 'suitable': 729,\n",
       " 'channels': 730,\n",
       " 'must': 731,\n",
       " 'made': 732,\n",
       " 'videos': 733,\n",
       " 'localization': 734,\n",
       " 'typically': 735,\n",
       " 'combined': 736,\n",
       " 'effects': 737,\n",
       " 'modern': 738,\n",
       " 'proposes': 739,\n",
       " 'real-time': 740,\n",
       " 'internet': 741,\n",
       " 'full': 742,\n",
       " 'spectral': 743,\n",
       " 'retrieval': 744,\n",
       " 'every': 745,\n",
       " 'gaussian': 746,\n",
       " 'independent': 747,\n",
       " 'concepts': 748,\n",
       " 'levels': 749,\n",
       " 'spectrum': 750,\n",
       " 'storage': 751,\n",
       " 'methodology': 752,\n",
       " 'areas': 753,\n",
       " 'property': 754,\n",
       " 'tree': 755,\n",
       " 'bayesian': 756,\n",
       " 'together': 757,\n",
       " 'people': 758,\n",
       " 'evolution': 759,\n",
       " 'idea': 760,\n",
       " 'policies': 761,\n",
       " 'whose': 762,\n",
       " 'include': 763,\n",
       " 'shared': 764,\n",
       " 'positive': 765,\n",
       " 'fixed': 766,\n",
       " 'event': 767,\n",
       " 'formulation': 768,\n",
       " 'direct': 769,\n",
       " 'extend': 770,\n",
       " 'understand': 771,\n",
       " 'approximate': 772,\n",
       " 'success': 773,\n",
       " 'arbitrary': 774,\n",
       " 'lack': 775,\n",
       " 'encoder': 776,\n",
       " 'despite': 777,\n",
       " 'entropy': 778,\n",
       " 'generalization': 779,\n",
       " 'factor': 780,\n",
       " 'scene': 781,\n",
       " 'usage': 782,\n",
       " 'platform': 783,\n",
       " 'shape': 784,\n",
       " 'namely': 785,\n",
       " 'engineering': 786,\n",
       " 'automated': 787,\n",
       " 'extracted': 788,\n",
       " 'alternative': 789,\n",
       " 'extract': 790,\n",
       " 'delay': 791,\n",
       " 'link': 792,\n",
       " 'lead': 793,\n",
       " 'topic': 794,\n",
       " 'learns': 795,\n",
       " 'complete': 796,\n",
       " 'aims': 797,\n",
       " 'errors': 798,\n",
       " 'region': 799,\n",
       " 'hence': 800,\n",
       " 'simultaneously': 801,\n",
       " 'version': 802,\n",
       " 'parameter': 803,\n",
       " 'instance': 804,\n",
       " 'elements': 805,\n",
       " 'define': 806,\n",
       " 'markov': 807,\n",
       " 'stability': 808,\n",
       " 'consists': 809,\n",
       " 'compute': 810,\n",
       " 'activities': 811,\n",
       " 'particularly': 812,\n",
       " 'density': 813,\n",
       " 'links': 814,\n",
       " 'sufficient': 815,\n",
       " 'take': 816,\n",
       " 'scheduling': 817,\n",
       " 'relation': 818,\n",
       " 'attributes': 819,\n",
       " 'baseline': 820,\n",
       " 'findings': 821,\n",
       " 'total': 822,\n",
       " 'programs': 823,\n",
       " 'mapping': 824,\n",
       " 'questions': 825,\n",
       " 'convex': 826,\n",
       " 'structural': 827,\n",
       " 'cnns': 828,\n",
       " 'precision': 829,\n",
       " 'past': 830,\n",
       " 'inputs': 831,\n",
       " 'fields': 832,\n",
       " 'mean': 833,\n",
       " 'hierarchical': 834,\n",
       " 'manner': 835,\n",
       " 'uncertainty': 836,\n",
       " 'who': 837,\n",
       " 'connected': 838,\n",
       " 'build': 839,\n",
       " 'would': 840,\n",
       " 'rather': 841,\n",
       " 'maps': 842,\n",
       " 'estimates': 843,\n",
       " 'diverse': 844,\n",
       " 'illustrate': 845,\n",
       " 'operation': 846,\n",
       " 'robots': 847,\n",
       " 'presence': 848,\n",
       " 'competitive': 849,\n",
       " 'tested': 850,\n",
       " 'predictive': 851,\n",
       " 'appropriate': 852,\n",
       " 'improving': 853,\n",
       " 'enable': 854,\n",
       " '3': 855,\n",
       " 'sequential': 856,\n",
       " 'extraction': 857,\n",
       " 'resolution': 858,\n",
       " 'ii': 859,\n",
       " 'suggest': 860,\n",
       " 'response': 861,\n",
       " 'cluster': 862,\n",
       " 'generating': 863,\n",
       " 'predictions': 864,\n",
       " 'another': 865,\n",
       " 'encoding': 866,\n",
       " 'construct': 867,\n",
       " 'relative': 868,\n",
       " 'unknown': 869,\n",
       " 'pairs': 870,\n",
       " 'e.g': 871,\n",
       " 'performs': 872,\n",
       " 'noisy': 873,\n",
       " 'implement': 874,\n",
       " 'pattern': 875,\n",
       " 'short': 876,\n",
       " 'clusters': 877,\n",
       " 'iot': 878,\n",
       " 'virtual': 879,\n",
       " 'contrast': 880,\n",
       " 'kernel': 881,\n",
       " 'i.e': 882,\n",
       " 'mathematical': 883,\n",
       " 'attack': 884,\n",
       " 'static': 885,\n",
       " 'art': 886,\n",
       " 'corpus': 887,\n",
       " 'improvements': 888,\n",
       " 'capabilities': 889,\n",
       " 'geometric': 890,\n",
       " 'matrices': 891,\n",
       " 'decomposition': 892,\n",
       " 'next': 893,\n",
       " 'block': 894,\n",
       " 'product': 895,\n",
       " 'ones': 896,\n",
       " 'labeled': 897,\n",
       " 'hidden': 898,\n",
       " 'sensors': 899,\n",
       " 'controller': 900,\n",
       " 'capable': 901,\n",
       " 'twitter': 902,\n",
       " 'last': 903,\n",
       " 'determine': 904,\n",
       " 'score': 905,\n",
       " 'conducted': 906,\n",
       " 'vectors': 907,\n",
       " 'reduced': 908,\n",
       " 'mining': 909,\n",
       " 'verification': 910,\n",
       " 'survey': 911,\n",
       " 'per': 912,\n",
       " 'iterative': 913,\n",
       " 'classifiers': 914,\n",
       " 'takes': 915,\n",
       " 'weighted': 916,\n",
       " 'exploit': 917,\n",
       " 'showing': 918,\n",
       " 'least': 919,\n",
       " 'ratio': 920,\n",
       " 'constraint': 921,\n",
       " 'location': 922,\n",
       " 'extended': 923,\n",
       " 'benefits': 924,\n",
       " 'family': 925,\n",
       " 'rely': 926,\n",
       " 'spaces': 927,\n",
       " 'relationship': 928,\n",
       " 'news': 929,\n",
       " 'mechanisms': 930,\n",
       " 'transformation': 931,\n",
       " 'handle': 932,\n",
       " 'combining': 933,\n",
       " 'etc': 934,\n",
       " 'differences': 935,\n",
       " 'gain': 936,\n",
       " 'expression': 937,\n",
       " 'collection': 938,\n",
       " 'humans': 939,\n",
       " 'construction': 940,\n",
       " 'propagation': 941,\n",
       " 'smart': 942,\n",
       " 'intelligence': 943,\n",
       " 'generalized': 944,\n",
       " 'previously': 945,\n",
       " 'limitations': 946,\n",
       " 'allocation': 947,\n",
       " 'brain': 948,\n",
       " 'groups': 949,\n",
       " 'structured': 950,\n",
       " 'explicit': 951,\n",
       " 'easily': 952,\n",
       " 'characterize': 953,\n",
       " 'fact': 954,\n",
       " 'compression': 955,\n",
       " 'edges': 956,\n",
       " 'trajectories': 957,\n",
       " 'create': 958,\n",
       " 'needs': 959,\n",
       " 'larger': 960,\n",
       " 'parts': 961,\n",
       " 'camera': 962,\n",
       " 'allowing': 963,\n",
       " 'realistic': 964,\n",
       " 'adaptation': 965,\n",
       " 'label': 966,\n",
       " 'far': 967,\n",
       " 'following': 968,\n",
       " 'dense': 969,\n",
       " 'introduces': 970,\n",
       " 'polynomial': 971,\n",
       " 'great': 972,\n",
       " 'variable': 973,\n",
       " 'computationally': 974,\n",
       " 'throughput': 975,\n",
       " 'increasingly': 976,\n",
       " 'protocols': 977,\n",
       " 'color': 978,\n",
       " 'consumption': 979,\n",
       " 'simulated': 980,\n",
       " 'observations': 981,\n",
       " 'partial': 982,\n",
       " 'needed': 983,\n",
       " 'indicate': 984,\n",
       " 'perspective': 985,\n",
       " 'notion': 986,\n",
       " 'imaging': 987,\n",
       " 'crucial': 988,\n",
       " 'steps': 989,\n",
       " 'proof': 990,\n",
       " 'advantage': 991,\n",
       " 'risk': 992,\n",
       " 'described': 993,\n",
       " 'final': 994,\n",
       " 'base': 995,\n",
       " 'utility': 996,\n",
       " 'embeddings': 997,\n",
       " 'desired': 998,\n",
       " 'condition': 999,\n",
       " 'settings': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (37551, 60)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(df['p_text'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_LENGTH, padding='post')\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (37551, 6)\n"
     ]
    }
   ],
   "source": [
    "label_encoder = MultiLabelBinarizer()\n",
    "enc = label_encoder.fit_transform(df['label'])\n",
    "# Y = to_categorical(enc)\n",
    "Y = enc.astype(\"float32\")\n",
    "\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30040, 60) (30040, 6)\n",
      "(7511, 60) (7511, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 22)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in word_model.vocab:\n",
    "        embedding_matrix[i] = word_model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32939, 300)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "nonzero_elements = np.count_nonzero(np.count_nonzero(embedding_matrix[:N], axis=1))\n",
    "nonzero_elements / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.count_nonzero(embedding_matrix[:N], axis=1)\n",
    "idx = np.where(aa == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in word_index.items():\n",
    "    if val in idx:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lstm_atten(embedding_matrix):\n",
    "    inp = Input(shape=(MAX_LENGTH,))\n",
    "    x = Embedding(vocab_size, EMBEDDING_DIM, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
    "    x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "    x = AttentionWithContext()(x)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = Dense(classes, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cnn(embedding_matrix):\n",
    "    filter_sizes = [1,2,3,5]\n",
    "    num_filters = 36\n",
    "\n",
    "    inp = Input(shape=(maxlen,))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = Reshape((maxlen, embed_size, 1))(x)\n",
    "\n",
    "    maxpool_pool = []\n",
    "    for i in range(len(filter_sizes)):\n",
    "        conv = Conv2D(num_filters, kernel_size=(filter_sizes[i], embed_size),\n",
    "                                     kernel_initializer='he_normal', activation='elu')(x)\n",
    "        maxpool_pool.append(MaxPool2D(pool_size=(maxlen - filter_sizes[i] + 1, 1))(conv))\n",
    "\n",
    "    z = Concatenate(axis=1)(maxpool_pool)   \n",
    "    z = Flatten()(z)\n",
    "    z = Dropout(0.1)(z)\n",
    "\n",
    "    outp = Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lstm_du(embedding_matrix):\n",
    "    inp = Input(shape=(maxlen,))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    '''\n",
    "    Here 64 is the size(dim) of the hidden state vector as well as the output vector. Keeping return_sequence we want the output for the entire sequence. So what is the dimension of output for this layer?\n",
    "        64*70(maxlen)*2(bidirection concat)\n",
    "    CuDNNLSTM is fast implementation of LSTM layer in Keras which only runs on GPU\n",
    "    '''\n",
    "    x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    conc = Dense(64, activation=\"relu\")(conc)\n",
    "    conc = Dropout(0.1)(conc)\n",
    "    outp = Dense(1, activation=\"sigmoid\")(conc)\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Network.summary of <keras.engine.training.Model object at 0x000001F4D7E4C6C8>>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN = model_lstm_atten(embedding_matrix)\n",
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN = model_lstm_atten(embedding_matrix)\n",
    "RNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 6\n",
    "batch_size = 32\n",
    "\n",
    "# cost time calculation\n",
    "start = time.time()\n",
    "\n",
    "history = RNN.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_test, Y_test), callbacks=[metrics, csv_logger])\n",
    "\n",
    "print(f'time : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pclightyear\\Anaconda3\\envs\\Data_Mining\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pre-train embedding\n",
    "embedding_layer = Embedding(vocab_size, \n",
    "                            EMBEDDING_DIM, \n",
    "                            weights=[embedding_matrix],\n",
    "#                             mask_zero=True,\n",
    "                            input_length=MAX_LENGTH, \n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 2\n",
    "filters = 256\n",
    "pool_size = 2\n",
    "\n",
    "# hidden_nodes = int(2/3 * (MAX_LENGTH * EMBEDDING_DIM))\n",
    "hidden_nodes = 128\n",
    "classes = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30040 samples, validate on 7511 samples\n",
      "Epoch 1/8\n",
      "30040/30040 [==============================] - 14s 456us/step - loss: 0.3490 - acc: 0.8515 - val_loss: 0.3262 - val_acc: 0.8631\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75      2166\n",
      "           1       0.72      0.02      0.04       825\n",
      "           2       0.64      0.57      0.60      2212\n",
      "           3       0.66      0.33      0.44      1439\n",
      "           4       0.85      0.08      0.15       132\n",
      "           5       0.74      0.55      0.63      1910\n",
      "\n",
      "   micro avg       0.70      0.51      0.59      8684\n",
      "   macro avg       0.72      0.38      0.43      8684\n",
      "weighted avg       0.70      0.51      0.56      8684\n",
      " samples avg       0.58      0.54      0.55      8684\n",
      "\n",
      "0.5906164974450859\n",
      "Epoch 2/8\n",
      "  512/30040 [..............................] - ETA: 11s - loss: 0.3102 - acc: 0.8662"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pclightyear\\Anaconda3\\envs\\Data_Mining\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30040/30040 [==============================] - 12s 413us/step - loss: 0.3114 - acc: 0.8684 - val_loss: 0.3152 - val_acc: 0.8652\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75      2166\n",
      "           1       0.48      0.18      0.26       825\n",
      "           2       0.68      0.54      0.60      2212\n",
      "           3       0.71      0.21      0.33      1439\n",
      "           4       0.72      0.14      0.23       132\n",
      "           5       0.69      0.65      0.67      1910\n",
      "\n",
      "   micro avg       0.71      0.52      0.60      8684\n",
      "   macro avg       0.68      0.41      0.47      8684\n",
      "weighted avg       0.69      0.52      0.57      8684\n",
      " samples avg       0.57      0.54      0.54      8684\n",
      "\n",
      "0.5961295471171112\n",
      "Epoch 3/8\n",
      "30040/30040 [==============================] - 13s 420us/step - loss: 0.2918 - acc: 0.8770 - val_loss: 0.3153 - val_acc: 0.8666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.67      0.74      2166\n",
      "           1       0.54      0.12      0.20       825\n",
      "           2       0.69      0.52      0.59      2212\n",
      "           3       0.57      0.52      0.54      1439\n",
      "           4       0.68      0.13      0.22       132\n",
      "           5       0.73      0.58      0.64      1910\n",
      "\n",
      "   micro avg       0.71      0.53      0.60      8684\n",
      "   macro avg       0.67      0.42      0.49      8684\n",
      "weighted avg       0.70      0.53      0.59      8684\n",
      " samples avg       0.58      0.55      0.56      8684\n",
      "\n",
      "0.6029188403882981\n",
      "Epoch 4/8\n",
      "30040/30040 [==============================] - 13s 425us/step - loss: 0.2694 - acc: 0.8872 - val_loss: 0.3176 - val_acc: 0.8670\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.72      0.75      2166\n",
      "           1       0.43      0.25      0.31       825\n",
      "           2       0.66      0.62      0.64      2212\n",
      "           3       0.65      0.41      0.51      1439\n",
      "           4       0.76      0.10      0.17       132\n",
      "           5       0.72      0.58      0.65      1910\n",
      "\n",
      "   micro avg       0.69      0.56      0.62      8684\n",
      "   macro avg       0.67      0.45      0.50      8684\n",
      "weighted avg       0.68      0.56      0.61      8684\n",
      " samples avg       0.60      0.58      0.58      8684\n",
      "\n",
      "0.6181285432193132\n",
      "Epoch 5/8\n",
      "30040/30040 [==============================] - 12s 411us/step - loss: 0.2400 - acc: 0.9009 - val_loss: 0.3321 - val_acc: 0.8634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74      2166\n",
      "           1       0.48      0.20      0.28       825\n",
      "           2       0.63      0.66      0.65      2212\n",
      "           3       0.61      0.43      0.50      1439\n",
      "           4       0.44      0.13      0.20       132\n",
      "           5       0.69      0.59      0.63      1910\n",
      "\n",
      "   micro avg       0.67      0.57      0.62      8684\n",
      "   macro avg       0.60      0.45      0.50      8684\n",
      "weighted avg       0.66      0.57      0.60      8684\n",
      " samples avg       0.61      0.60      0.59      8684\n",
      "\n",
      "0.6164007976071785\n",
      "Epoch 6/8\n",
      "30040/30040 [==============================] - 12s 412us/step - loss: 0.2027 - acc: 0.9177 - val_loss: 0.3660 - val_acc: 0.8550\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.64      0.71      2166\n",
      "           1       0.43      0.33      0.37       825\n",
      "           2       0.66      0.56      0.60      2212\n",
      "           3       0.54      0.49      0.51      1439\n",
      "           4       0.41      0.16      0.23       132\n",
      "           5       0.66      0.56      0.61      1910\n",
      "\n",
      "   micro avg       0.65      0.54      0.59      8684\n",
      "   macro avg       0.58      0.46      0.51      8684\n",
      "weighted avg       0.65      0.54      0.59      8684\n",
      " samples avg       0.58      0.56      0.56      8684\n",
      "\n",
      "0.5895873893110595\n",
      "Epoch 7/8\n",
      "30040/30040 [==============================] - 12s 412us/step - loss: 0.1586 - acc: 0.9379 - val_loss: 0.4124 - val_acc: 0.8494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.69      0.73      2166\n",
      "           1       0.34      0.34      0.34       825\n",
      "           2       0.60      0.65      0.62      2212\n",
      "           3       0.54      0.46      0.50      1439\n",
      "           4       0.45      0.16      0.23       132\n",
      "           5       0.66      0.57      0.61      1910\n",
      "\n",
      "   micro avg       0.62      0.57      0.59      8684\n",
      "   macro avg       0.56      0.48      0.51      8684\n",
      "weighted avg       0.62      0.57      0.59      8684\n",
      " samples avg       0.59      0.60      0.58      8684\n",
      "\n",
      "0.5944072657743785\n",
      "Epoch 8/8\n",
      "30040/30040 [==============================] - 12s 409us/step - loss: 0.1162 - acc: 0.9565 - val_loss: 0.4719 - val_acc: 0.8460\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      2166\n",
      "           1       0.35      0.35      0.35       825\n",
      "           2       0.64      0.54      0.58      2212\n",
      "           3       0.50      0.50      0.50      1439\n",
      "           4       0.30      0.17      0.21       132\n",
      "           5       0.63      0.59      0.61      1910\n",
      "\n",
      "   micro avg       0.61      0.57      0.59      8684\n",
      "   macro avg       0.53      0.48      0.50      8684\n",
      "weighted avg       0.61      0.57      0.59      8684\n",
      " samples avg       0.59      0.59      0.57      8684\n",
      "\n",
      "0.5874450124836523\n",
      "time : 110.08999967575073 sec\n"
     ]
    }
   ],
   "source": [
    "RNN = Sequential()\n",
    "# RNN.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "RNN.add(embedding_layer)\n",
    "\n",
    "# RNN.add(CuDNNLSTM(hidden_nodes, return_sequences=True))\n",
    "# RNN.add(CuDNNLSTM(int(hidden_nodes/2)))\n",
    "# RNN.add(Bidirectional(CuDNNLSTM(int(hidden_nodes))))\n",
    "RNN.add(Bidirectional(CuDNNGRU(hidden_nodes, return_sequences=True)))\n",
    "RNN.add(Bidirectional(CuDNNGRU(hidden_nodes)))\n",
    "# RNN.add(Bidirectional(CuDNNLSTM(hidden_nodes, return_sequences=True)))\n",
    "# RNN.add(Bidirectional(CuDNNLSTM(int(hidden_nodes/2))))\n",
    "# RNN.add(Dense(hidden_nodes, activation='relu'))\n",
    "\n",
    "# RNN.add(Dropout(0.2))\n",
    "# RNN.add(Dense(hidden_nodes, activation='relu'))\n",
    "\n",
    "# RNN.add(Concatenate([GlobalAveragePooling1D(), GlobalMaxPooling1D()]))\n",
    "\n",
    "# Pool1 = Sequential()\n",
    "# Pool1.add(GlobalAveragePooling1D())\n",
    "\n",
    "# Pool2 = Sequential()\n",
    "# Pool2.add(GlobalMaxPooling1D())\n",
    "\n",
    "# Pool = Concatenate([Pool1, Pool2])\n",
    "\n",
    "# RNN.add(Pool)\n",
    "# RNN.add(Dense(hidden_nodes, activation='relu'))\n",
    "# RNN.add(Dropout(0.1))\n",
    "\n",
    "RNN.add(Dense(classes, activation='sigmoid'))\n",
    "RNN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "epochs = 8\n",
    "batch_size = 32\n",
    "\n",
    "# cost time calculation\n",
    "start = time.time()\n",
    "\n",
    "# RNN.summary()\n",
    "\n",
    "history = RNN.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_test, Y_test), callbacks=[metrics, csv_logger])\n",
    "\n",
    "print(f'time : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.851509</td>\n",
       "      <td>0.349044</td>\n",
       "      <td>0.863112</td>\n",
       "      <td>0.326181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.868448</td>\n",
       "      <td>0.311365</td>\n",
       "      <td>0.865242</td>\n",
       "      <td>0.315208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.877042</td>\n",
       "      <td>0.291757</td>\n",
       "      <td>0.866573</td>\n",
       "      <td>0.315335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.887228</td>\n",
       "      <td>0.269400</td>\n",
       "      <td>0.866973</td>\n",
       "      <td>0.317622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.900871</td>\n",
       "      <td>0.239993</td>\n",
       "      <td>0.863400</td>\n",
       "      <td>0.332058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch       acc      loss   val_acc  val_loss\n",
       "0      0  0.851509  0.349044  0.863112  0.326181\n",
       "1      1  0.868448  0.311365  0.865242  0.315208\n",
       "2      2  0.877042  0.291757  0.866573  0.315335\n",
       "3      3  0.887228  0.269400  0.866973  0.317622\n",
       "4      4  0.900871  0.239993  0.863400  0.332058"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the training log\n",
    "training_log = pd.DataFrame()\n",
    "training_log = pd.read_csv(\"logs/training_log.csv\")\n",
    "training_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "# plot validation macro fl score per epoch\n",
    "# plt.subplot(121)\n",
    "index = np.arange(epochs)\n",
    "plt.plot(index, metrics.val_f1s, marker='', color='r', linewidth=2)\n",
    "\n",
    "plt.title('Training micro fl score per epoch')\n",
    "\n",
    "# plot training and validation loss per epoch\n",
    "# plt.subplot(122)\n",
    "# plt.plot('epoch', 'loss', data=training_log, marker='', color='b', linewidth=2)\n",
    "# plt.plot('epoch', 'val_loss', data=training_log , marker='', color='r', linewidth=2)\n",
    "\n",
    "# plt.title('Training Loss per epoch')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()  \n",
    "plt.savefig('f1score_per_epoch.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_json = model.to_json()\n",
    "with open(\"models/RNN_v1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"models/RNN_v1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN\n",
    "df = test_df\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (9316, 60)\n"
     ]
    }
   ],
   "source": [
    "X_private_test = tokenizer.texts_to_sequences(df['p_text'].values)\n",
    "X_private_test = pad_sequences(X_private_test, maxlen=MAX_LENGTH, padding='post')\n",
    "print('Shape of data tensor:', X_private_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_private_test_pred = model.predict(X_private_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_private_test_pred_de = label_decode(label_encoder, Y_private_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = label_encoder.transform(df['label'])\n",
    "y_pred = Y_private_test_pred_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVES', 'OTHERS',\n",
       "       'RESULTS'], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  BACKGROUND       0.75      0.69      0.72      2709\n",
      " CONCLUSIONS       0.39      0.19      0.26      1042\n",
      "     METHODS       0.60      0.65      0.62      2585\n",
      "  OBJECTIVES       0.62      0.41      0.49      1887\n",
      "      OTHERS       0.35      0.18      0.24       179\n",
      "     RESULTS       0.65      0.61      0.63      2349\n",
      "\n",
      "   micro avg       0.64      0.56      0.60     10751\n",
      "   macro avg       0.56      0.46      0.49     10751\n",
      "weighted avg       0.63      0.56      0.58     10751\n",
      " samples avg       0.60      0.58      0.58     10751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_true, y_pred=y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6087408408252352\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_true, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "# load json and create model\n",
    "json_file = open('models/RNN_v1.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"models/RNN_v1.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131166"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(public_test_df)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model\n",
    "df = public_test_df\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (131166, 60)\n"
     ]
    }
   ],
   "source": [
    "X_public_test = tokenizer.texts_to_sequences(df['p_text'].values)\n",
    "X_public_test = pad_sequences(X_public_test, maxlen=MAX_LENGTH, padding='post')\n",
    "print('Shape of data tensor:', X_public_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_public_test_pred = model.predict(X_public_test, batch_size=batch_size)\n",
    "Y_public_test_pred_de = label_decode(label_encoder, Y_public_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131166, 6)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = Y_public_test_pred_de\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVES', 'OTHERS',\n",
       "       'RESULTS'], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, task in enumerate(label_encoder.classes_):\n",
    "    test_submission.loc[:N-1, task] = y_pred[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>BACKGROUND</th>\n",
       "      <th>OBJECTIVES</th>\n",
       "      <th>METHODS</th>\n",
       "      <th>RESULTS</th>\n",
       "      <th>CONCLUSIONS</th>\n",
       "      <th>OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T00001_S001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T00001_S002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T00001_S003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T00001_S004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T00001_S005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      order_id  BACKGROUND  OBJECTIVES  METHODS  RESULTS  CONCLUSIONS  OTHERS\n",
       "0  T00001_S001           1           0        0        0            0       0\n",
       "1  T00001_S002           1           0        0        0            0       0\n",
       "2  T00001_S003           0           0        0        0            0       0\n",
       "3  T00001_S004           0           1        0        0            0       0\n",
       "4  T00001_S005           0           0        0        1            0       0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "import keras.backend as K\n",
    "\n",
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatible with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "    \n",
    "\n",
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Data Mining)",
   "language": "python",
   "name": "data_mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
